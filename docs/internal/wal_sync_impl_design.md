
# 1. WAL同期の実装設計

## 1.1 概要

本ドキュメントはレプリカのWAL同期機能の実装レベルの設計方針をまとめたものである。

本ドキュメントは最初の実装作業用に作成したもので、その後の修正に追従してドキュメントを
修正する予定はない。したがって、実装とドキュメントが乖離している可能性があるが、
初期実装時の設計方針は残しておく価値があるためリポジトリに保持する。


## 1.2 機能コンポーネント


### 1.2.1 リモートバックアップサービス

* Epoch値の提供
  * Tsurugiがオンラインの場合は、limestoneのdatastoreのatomic変数の値を返す。
    * この変数値は、「EpochファイルのEpochと同じ値」、「Epochファイルの更新前の値」のどちらかであることが保証される。
  * Tsurugiがオフラインの場合は、Epochファイルからdurable Epoch値を取得し、返す

* WAL の互換性情報の提供
  * 詳細は、[3.2 WALの履歴情報の保持方法](#32-walの履歴情報の保持方法)に記述

* セッション
  * セッションの必要性
    * リソース管理
      * バックアップ時に保持しておく必要があるリソースを、セッションで管理する
      * バックアップ終了時にリソースを開放する
      * バックアップが終了しない場合でも、セッションのタイムアウトによりリソースを開放する
  * バックアップ対象のリスト返却時にセッショントークンとセッションの有効期限を返す
    * セッションの有効期間はクライアントからの要求により更新可能
  * セッションの有効期間は秒などの単位で設定ファイル等で指定可能とし、現在時刻から指定された期間後まで有効とする。
* バックアップ関連
  * 増分バックアップの要求
    * 開始Epochと終了Epochを指定して、バックアップ対象のオブジェクトのリストを提供する
  * フルバックアップの要求 => バックアップ要求時点で最新のデータを復元するために必要なオブジェクトのリストを提供する
  * オブジェクトのリストには以下を含む
    * メタデータ
    * WALファイル
    * スナップショット
    * BLOB ファイル
    * 他


* 増分バックアップとWALファイルの問題
  * 現行のWALファイルは、ファイルを先頭から読んでいかないと、当該WALファイルに記録されているEpoch値がわからないが、先頭から読むと性能が悪い
  * 詳細は[3.1 指定のEpoch値からWALファイルを読む方法](#31-指定のepoch値からwalファイルを読む方法)と合わせて決定するが、現時点ではlocatorファイルを用意する方式が良いと考えている

* オブジェクトデータのコピー
  - クライアントの要求に基づき、オブジェクトをクライアントにコピーする。
    - クライアントがバックアップ要求時に返されたオブジェクトのリストを指定してコピーを要求することを想定している。
    - オブジェクトは必ずしもファイルではなく、ファイルの一部 (WAL ファイルの区間) である場合もある
  - 複数のコピー方式に対応可能な設計とし、将来的には RDMA などの高速転送手段にも対応する。
  - UCX のような、RDMA や TCP など異なる通信方式を統一的に扱う単一 API を提供する通信フレームワークの利用も将来の検討事項とする。
  - 初期実装では、工数が少ない方式を採用する。
    - 候補：  
      1. gRPC のServer Streaming RPCを利用してコピーする方法(ファイルのチャンクを分割して転送する)  
      2. 最低限のレプリケーション機能の BLOB コピー機能を流用する方法
    - Server Streaming RPCを簡易評価した上で、採用方式を決定する。
  - どのようなコピー手段が利用可能かをクライアントが知る必要があるが、初期実装では方式が 1 種類のみのため、この機能は不要とする。
  - コピーはクライアント要求と非同期で実行する。
  - クライアントからのコピー状況照会要求に応答する。
  - セッションタイムアウトが発生した場合はコピーを停止する。  
    即時停止ではなく、その時点でコピー中のオブジェクトを完了させてから停止してもよい。クライアントの実装上の都合（主にリカバリ処理）によって仕様を決定する。少なくともセッションタイムアウト後は、新しいオブジェクトの転送が不可能。





### 1.2.2 レプリカ同期クライアント

* リモートバックアップサービスを通して、リモートノードのEpoch値を取得、表示
* 自ノードのEpoch値の取得、表示
  * Epochファイルからdurable Epoch値を取得し、返す
  * 将来的にレプリカも Tsurugi インスタンスが稼働しているケースがありうるが、そのときは「リモートバックアップサービスと同様」とする。
* WAL の互換性を検証
  * リモートバックアップサービスからWALの互換性情報を取得
  * 自ノードのWALの互換性情報と一致するか確認する
    * 自ノードと、リモートバックアップサービスが共通の履歴を持っていればOK
    * 最初のバージョンでは、自ノードの履歴とリモートバックアップサービスの途中までの履歴が完全に一致している場合のみOKとする
  * 初期バージョンは、一致しない場合、フルバックアップを用いたリストアを行う。
    * 将来的には次の機能を提供することにより、分岐した場所までrewindしたのち同期可能にする。
      * 特定のEpochまでWALをrewindする機能
      * rewindするEpochを特定するための情報表示(ブランチしたEpochのEpochと時刻を表示など)


* WAL同期機能
  * 以下の処理を実行する
  * リモートバックアップサービスからバックアップ対象のオブジェクトリストを取得
    * 開始Epochと終了Epochを指定して、増分バックアップ対象のオブジェクトのリストを取得する
    * フルバックアップを指定し、フルバックアップ対象のオブジェクトのリストを取得する
    * オブジェクトのリストともにセッショントークンとセッションの有効期限を取得する
  * バックアップ対象のオブジェクトのコピーをリモートバックアップサービスに要求
    * サーバから取得したバックアップ対象のオブジェクトのリストをそのままコピー要求する
    * コピー方式と、コピーに必要なパラメータはクライアントが指定する
    * コピーが完了すると次の処理に移る
    * コピー完了までの間、セッションが有効期限切れにならないように適切なタイミングでセッションの有効期間の更新を要求する
  * 取得したファイルを自ノードのデータディレクトリに展開する
    * データディレクトリへの展開中に処理が中断した場合
      * 次回起動時に、中断があったことを検知し、以下のいずれかを可能にする。
        * 中断したファイルの展開を再開する
        * 展開の中止(展開前の状態に戻す)
    * 展開が終了(または中止)したら不要ファイルを削除する。
  * 増分バックアップを取得した場合
    * WALファイルの一部を部分的に取得するケースがあるので、対応が必要
      * 自ノードのWALファイルはローテーションする
      * 同一ファイル名のファイルが送られる可能性を排除できないので、上書きしないように制御が必要
      * マージ処理が必要 → WALのコンパクション機能を実行すれば良い、あるいは起動時に重複エントリを排除しても良い。
    * レプリカの起動高速化のために、WALのコンパクション処理を実行する（オプション）
      * ソート+重複データの削除を行う
      * 将来はスナップショットの更新処理になる


## 2. 実装詳細


### 2.1 WALの履歴情報の保持方法

* データベースの開始から、特定エポック/最新までのWALの互換性情報を提供する
* wal_historyという名称の履歴情報を保持するファイルを用意する
  * このファイルはバイナリファイルで、エポック、UUID、タイムスタンプを保持する。 
  * この機能をwal_historyクラスに実装する。
  * ここに記録するエポックは、起動時にスナップショット作成時に決定するdurable epochの値です。初期起動時は0になる。
  * このファイルはバックアップ対象に含めるので、バックアップ対象を決定するロジックを修正する。

### 2.2 WAL の互換性情報の提供

* wal_historyの結果を返すgRPCサービスを提供する。

## 3. 技術的課題と対策案


### 3.1 指定のEpoch値からWALファイルを読む方法

* Epoch指定での増分バックアップのために必要
  * 十分な性能が得られないことがあることを前提に今回の実装に含めないかもしれない。開発スケジュール作成時に決定する。
* 現時点では3方式を考えている。外部locator方式が良いと考えているが、十分検討が必要 ← レプリケーション以外の用途でも利用する
  * 外部locator方式
    * WALファイルとペアになるlocatorファイルを用意し、EpochIDと、WAL上の位置を記録する。locatorファイルのエントリを固定長にしてランダムアクセス可能にする
  * 境界マーカー方式
    * WALファイルを単独でランダムアクセス可能にする方式、その1
    * WALファイル内の定期的なバイト境界（例：1MBごと）に、直前のエントリのオフセット情報を埋め込む
    * エントリが境界をまたぐ場合に、エントリを分割してRead/Writeする必要がある
  * マーカー（埋め込み）方式
    * WALファイルを単独でランダムアクセス可能にする方式、その2
    * 特定のバイト列をEpochの位置にマーカーとして埋め込む
    * 読み取り時は、WALを後方または前方にスキャンして該当マーカーを探すことでEpochを特定する
    * 任意バイナリとの衝突を避けるため、マーカーの出現に対するエスケープ処理が必要となる
  * ページ方式
    * WALファイルを単独でランダムアクセス可能にする方式、その3
    * 現状のWALのRead/Writeのコードはファイルストリームに対するRead/Writeであるが、これを修正する。
    * ある程度の大きさのバッファを用意し、ストレージに対するI/Oはバッファ単位で行う。この単位をページと呼ぶ。
    * ページを固定長にすれば、ランダムアクセスが可能になる。
    * ページを可変長(この場合ページでなくチャンクと呼んだ方がよいかも)にして、ページ単位でランダムアクセス可能にすることもできる(詳細未検討)
    * 現行のRead/Writeのコードは、ページに対するcopy処理に置き換える。
    * 実装上、色々やることがあり面倒。
    * パフォーマンスは一番期待できる。




### 3.2 コンパクション処理

* WAL同期機能の実現にあたっては、コンパクション処理の実行時間が性能上の課題となる可能性がある。
* この問題はLimestone全体の性能課題として既に認識されており、WAL同期とは別の開発ステップで対応が予定されている。
* そのため、WAL同期機能の開発においては、コンパクション処理の最適化は行わない。


### 3.3 blobをオブジェクトのリストに含めるべきか

* BLOBのリストをオブジェクトのリストに含めず、WALファイル、スナップショットなどに含むBLOBを自動的にコピー対象とする案もある。
  * これには以下のメリットがある。
    * リストの巨大化しない。BLOBは100万とか、1億、それ以上の数になり得るが、それを考慮しなくても良い。
    * BLOBのリストを作成するのに、WALを走査する必要があり、時間がかかる。BLOBのリスト作成と、コピーで2回WALを読むことになる。
  * ただし、以上のメリットはすべて現状の実装に基づいたものであり、本質的とはいいがたい。


## 4. Walkthrough

* このセクションでは、想定するシナリオについて各コンポーネントがどのように動作するかを確認し、設計項目に漏れがないことを確認する。
* ここで提示するシナリオは、実装完了後のシナリオテストとしても使用する。
* このWalkthroughでは、最低限のレプリケーション機能を用いたレプリケーションの利用を想定する。


### 4.1 レプリカの再同期とマスタへの昇格


#### 4.1.1 シナリオ概要

1. ノードAがマスタ、ノードBがレプリカの構成
2. ノードBのレプリカ停止に伴う同期のズレが発生
    * ノードBのレプリカが停止
    * 現状のレプリケーション機能では、ノードBのレプリカ停止に伴い、ノードAのマスタも停止する
    * ノードAの設定を変更し単独動作(レプリカなし)で起動する
    * ノードAのDBを更新し同期のズレが発生する。
3. レプリカの再同期
    * 現状の設計では、再同期のためにマスタ、レプリカともに停止する必要があるので、ノードAのマスタを停止する。
    * WAL同期機能でノードAとノードBを同期する。
4. ノードAからノードBへのレプリケーションを再開する
    * ノードAの設定を変更し、ノードBがレプリカとして動作するようにする。
    * ノードBのレプリカを起動する
    * ノードAのマスタを起動する

以下のシナリオはWALの再同期とは直接関係ないが、再同期後にも
レプリケーションが正しく動作するかの検証のために、
マスタとレプリカの入れ替えを行う。

5. ノードBをマスタに昇格し、ノードAをレプリカとして動作させる。
    * ノードAのマスタを停止する
    * ノードBのレプリカを停止する
    * 各ノードの設定を変更し、ノードBがマスタ、ノードAがレプリカとして動作するようにする
    * ノードAでレプリカをする
    * ノードBでマスタを起動する

6. ノードAをマスタに昇格(復旧し)、ノードBをレプリカとして動作させる。
    * ノードBのマスタを停止する
    * ノードAのレプリカを停止する
    * 各ノードの設定を変更し、ノードAがマスタ、ノードBがレプリカとして動作するようにする
    * ノードBでレプリカを起動する
    * ノードAでマスタを起動する




#### 4.1.2 想定作業手順

* 準備
  * ノードAでマスタ、ノードBでレプリカを動作させる。
    * ノードBでレプリカを起動し、その後ノードAでTsurugiを起動する
  * ノードAのTsurugiのデータを更新し、レプリカに反映される
  * ノードBのレプリカを停止する。
  * レプリケーションに失敗し、ノードAのTsurugiが停止するため、Tsurugiをレプリカなしで起動する
  * TsurugiのDBを更新し、マスタとレプリカが同期していない状態になる
  * ノードAのTsurugiは単独（レプリカなし）で起動するが、Tsurugiを参照・更新するアプリは動作させない

* 再同期（これが本Walkthroughの対象）
  * ノードBのレプリカ同期クライアントが同期を実施：
    * ノードAのエポックを確認
    * ノードBのエポックを確認
    * WAL同期を実行：
      * 増分バックアップによる同期を行う
      * ノードAとノードBのWAL互換性を確認
      * 増分バックアップデータをノードAからノードBにコピー
  * ノードAマスタ、ノードBレプリカでTsurugiを起動する

* ノードBをマスタに昇格
  * ノードAのTsurugiを停止する
  * ノードAをノードBのレプリカとして動作させるようにTsurugiを設定する
  * ノードAでレプリカを起動し、その後ノードBでTsurugiを起動する
  * ノードBのTsurugiのデータを更新し、レプリカ（ノードA）にも反映される

* ノードAをマスタに昇格(復旧し)、ノードBをレプリカとして動作させる
  * ノードBのTsurugiを停止する
  * ノードBをノードAのレプリカとして動作するようにTsurugiを設定する
  * ノードBでレプリカを起動し、その後ノードAでTsurugiを起動する
  * ノードAのTsurugiのデータを更新し、レプリカ（ノードB）にも反映される


#### 4.1.3 再同期のWalkthrough

* ノードAのエポックを確認
  * レプリカ同期クライアントの「リモートノードのエポック取得・表示」機能を使用
    * リモートバックアップサービスの「エポック値の提供」機能を使用

* ノードBのエポックを確認
  * レプリカ同期クライアントの「自ノードのエポック取得・表示」機能を使用

* WAL同期 - ノードAとノードBのWAL互換性の確認
  * レプリカ同期クライアントが自ノードのWAL互換性情報を取得
  * リモートバックアップサービスがWAL互換性情報を提供
  * レプリカ同期クライアントが両者を比較して互換性を検証

* WAL同期 - 増分バックアップ対象のオブジェクトリストの取得とコピー
  * レプリカ同期クライアントが、開始エポックと終了エポックを指定して、バックアップ対象のオブジェクトリストを取得
    * リモートバックアップサービスは、対象オブジェクトのリスト、セッショントークン、およびセッションの有効期限を返す
  * レプリカ同期クライアントは、取得したオブジェクトについてリモートバックアップサービスにコピーを要求する
  * コピー完了までの間、以下を繰り返す：
    * コピーの進捗状況を照会(コピーの完了までポーリングする)
    * セッションの有効期限の延長を適宜要求
  * コピー完了後、レプリカ同期クライアントは取得したファイルを自ノードのデータディレクトリに展開する
  * セッションを終了し、レプリカ同期クライアントが終了する。

* ノードAマスタ、ノードBレプリカでTsurugiを起動する




### 4.2 新規レプリカの追加


#### 4.2.1 シナリオ概要

1. ノードAでレプリカなしの構成でTsurugiを運用し、データが更新される
2. WAL同期機能のフルバックアップによる同期を用いて、ノードAとノードBを同期する
    * フルバックアップ開始後もノードAは更新されるため、ノードAはノードBよりもEpoch値が進んでいる状態になる
3. 完全同期
    * 完全に同期するために、ノードAのマスタを停止する
    * 差分バックアップによるWAL同期を行い、ノードAとノードBを完全に同期する
4. レプリケーション開始
    * 各ノードの設定を変更し、ノードAがマスタ、ノードBがレプリカとして動作するようにする
    * ノードBでレプリカを起動する
    * 自ノードのデータディレクトリに展開する


#### 4.2.2 想定作業手順

* 準備
  * ノードA単独でTsurugiを起動する
  * アプリケーションを実行し、常にTsurugiの更新がかかる状態にする
  * ノードBにノードAと同一バージョンのTsurugiをインストールする

*  新規レプリカの追加(これが本Walkthroughの対象)
   * ノードBのレプリカ同期クライアントがフルバックアップからのリストアを実行
     * フルバックアップによる同期を行う。
     * セッションを終了し、レプリカ同期クライアントが終了する。
   * リストアの完了後に、ノードAのTsurugiのデータを更新するアプリケーションとノードAのTsurugiを停止する
     * フルバックアップ時点以降もノードAのTsurugiが更新されているため、ノードAのEpochは、ノードBのEpochよりも進んでいる状態になる
  * [レプリカの再同期とマスタへの昇格](#レプリカの再同期とマスタへの昇格)のWalkthroughと同様に、ノードBのレプリカ同期クライアントで同期を実施する
    * ノードAのエポックを確認
    * ノードBのエポックを確認
    * WAL同期を実行：
      * 増分バックアップによる同期を行う
      * ノードAとノードBのWAL互換性を確認
      * 増分バックアップデータをノードAからノードBにコピー
      * セッションを終了し、レプリカ同期クライアントが終了する。
   * ノードAのTsurugiを停止する。
   * ノードBをノードAのレプリカとして動作するようにTsurugiを設定する。
   * ノードBでレプリカを起動、その後ノードAでTsurugiを起動する。



#### 4.2.3 新規レプリカの追加のWalkthrough

* フルバックアップからのリストア
  * レプリカ同期クライアントが、フルバックアップ対象のオブジェクトリストを取得
    * リモートバックアップサービスは、フルバックアップの対象オブジェクトのリスト、セッショントークン、およびセッションの有効期限を返す
  * レプリカ同期クライアントは、取得したオブジェクトについてリモートバックアップサービスにコピーを要求する
  * コピー完了までの間、以下を繰り返す：
    * コピーの進捗状況を照会(コピーの完了までポーリングする)
    * セッションの有効期限の延長を適宜要求
  * コピー完了後、レプリカ同期クライアントは取得したファイルを自ノードのデータディレクトリに展開する

* WAL同期 - 増分バックアップ対象のオブジェクトリストの取得とコピー
  * レプリカ同期クライアントが、開始エポックと終了エポックを指定して、バックアップ対象のオブジェクトリストを取得
    * リモートバックアップサービスは、対象オブジェクトのリスト、セッショントークン、およびセッションの有効期限を返す
  * レプリカ同期クライアントは、取得したオブジェクトについてリモートバックアップサービスにコピーを要求する
  * コピー完了までの間、以下を繰り返す：
    * コピーの進捗状況を照会(コピーの完了までポーリングする)
    * セッションの有効期限の延長を適宜要求
  * コピー完了後、レプリカ同期クライアントは取得したファイルを自ノードのデータディレクトリに展開する



### 4.3 レプリカの巻き戻し

#### 4.3.1 シナリオ概要

なんらかの理由でレプリカのEpoch値が、マスターのEpoch値よりも進んでしまった場合に、レプリカのEpoch値を巻き戻す。
次のようなケースが考えられる。

1.  ノードAでバックアップからリストアを行った結果、最新Epochがバックアップ時点に巻き戻った
2. Tsurugiは、マスタとレプリカの(WALとEpochの)更新を並列に実行できる。このため、レプリカの更新が完了、
  マスタの更新が未完了という状態が発生しうる。この状態でノードAに障害が起きると、ノードAのEpoch値が
  ノードBのEpoch値よりも古い値になってしまう。


本シナリオでは、レプリカのEpochがマスターのEpoch値より進んだ原因を問わず、その状態から
復旧を行うことを目的とする。


1. レプリカが先行した状態を作成する
   * ノードAがマスタ、ノードBがレプリカの構成で運用する。
   * DBを更新する
   * ノードAのフルバックアップを取得する
   * DBを更新する
   * ノードAのマスタと、ノードBのレプリカを停止する
   * ノードAをフルバックアップからリストアする
2. 再同期
   * レプリカ同期クライアントで、ノードA, ノードBのepoch値を確認する
   * レプリカ同期クライアントで、ノードBのEpochをノードAのEpoch値に巻き戻す
   * ノードAがマスタ、ノードBのレプリカを起動する




#### 4.3.2 想定作業手順

* 準備
* ノードAとノードBの両方を初期状態（DBデータが空）でレプリケーション構成とする
* ノードAでマスタ、ノードBでレプリカを動作させる
* ノードAのTsurugiのバックアップを取得する
  * フルバックアップを取得する
  * バックアップの取得方法（オンライン、オフライン）は問わない
  * 必要に応じてノードBのレプリカを停止し、再開する
* 再度アプリケーションを実行してエポックを進める
* ノードAとノードBを停止し、ノードAをバックアップからリストアする
* レプリカの巻き戻しパターン1(これが本Walkthroughの対象)
  * ノードA、ノードBのレプリカ同期クライアントで、Epochを確認する
    * ノードBのEpochがノードAのEpochよりも進んでいることを確認する
  * WAL同期を実行
    * フルバックアップによる同期を行う
    * バックアップデータをノードAからノードBにコピー
    * セッションを終了し、レプリカ同期クライアントが終了する
  * ノードBでレプリカを起動、その後ノードAでTsurugiを起動する
* レプリカの巻き戻しパターン2(これが本Walkthroughの対象)
  * パターン1との違いは、フルバックアップによる同期ではなく、Epochのrewindによる同期を行うこと
  * レプリカ同期クライアントのrewind機能により、ノードBのEpoch値をノードAのEpoch値に巻き戻す
  * ノードBでレプリカを起動、その後ノードAでTsurugiを起動する


#### 4.3.3 レプリカの巻き戻しパターン1のWalkthrough

**フルバックアップからのリストアによる巻き戻し**

基本的な動作は[§4.2.2 新規レプリカの追加のWalkthrough](#422-新規レプリカの追加のwalkthrough)と同様であるが、以下の点が異なる。

  * 展開先のディレクトリに、すでにデータファイルが存在すること
  * フルバックアップのコピー完了後に、データファイルを更新するとき、次の療法がかのうでなければならない
    * 途中で中断したときに、redo, undoの処理が可能であること
      * redo: 中途半端な状態から、ただしく同期がとれた状態に戻す
      * undo: 操作前の状態に戻す



#### 4.3.4 レプリカの巻き戻しパターン2のWalkthrough

* レプリカ同期クライアント単独で指定のEpoch値までEpoch値を巻き戻す
* レプリカ同期コマンドでこの機能を呼び出すと、指定のEpoch値より大きい値を削除し、指定のEpoch値まで巻き戻す
  * 具体的な内容は本機能の設計完了後に決定する
* レプリカ同期クライアントの本機能には、事前調査機能を実装する
  * 指定のEpoch値まで巻き戻すかどうかを確認する
  * 巻き戻しが不可能な場合は、フルバックアップからのリストアによる巻き戻しを行う
    * 巻き戻しが不可能な場合の有無については設計時に判明すると考え、現時点ではWalkthroughに含めている。発生しない場合はWalkthroughから除外する
* 本機能が中断した場合、redoおよびundoの処理が可能でなければならない
  * redoは中途半端な状態から正しく巻き戻された状態に戻すことを指す
  * undoは操作前の状態に戻すことを指す



## 5. 開発タスク・工数見積もり

* このセクションでは実装が必要な開発タスクの概要、および工数見積もりについて記述する。
* 開発期間に関しては以下の条件で見積もる
  * エフォート率60程度を想定する
  * 各タスクのUT作成までとする
  * リスクは積まない
* 1Day = 8H, 1Week = 5Days



### 5.1 WALのランダムアクセス化



*  [3.1 指定のEpoch値からWALファイルを読む方法](#31-指定のepoch値からwalファイルを読む方法)で検討した方式のうち、以下の3方式について論じる。マーカー（埋め込み）方式は、メリットが少ないので検討しない。
   *  外部locator方式
   *  境界マーカー方式
   *  ページ方式
* 外部locator方式の開発期間は3.5日
* 境界マーカー方式
  * 現行のファイルストリームに対するRead/Writeのコードを変更せず、Read/Write対象のストリームを境界マーカ対応のストリームに置き換える
  * 修正箇所が少なく開発コストが低い
  * 開発期間は5日
* ページ方式
  * 詳細未検討だが3Week程度必要。
  * 修正箇所が多く、さらにテストが面倒（難しいわけではないが、大量のテストが必要）。
* WALのランダムアクセス化により、起動時のインデックス生成やスナップショット、コンパクションの効率化も可能になると考えるが、その作業は見積もりに含んでいない。レプリケーションの同期に必要な分の工数のみ見ている。
  * とはいえ、どの方式にするかにより、レプリケーション同期以外の処理の効率化の作業工数や、期待性能に影響があるので、ある程度はそれを見込んで、方式を決定する必要がある。
* レプリケーション同期機能を早く実現したいなら、WALのランダムアクセス化をしないという選択肢もある。



### 5.2 WALフォーマット変換

* WALのランダムアクセス化により新旧フォーマットの互換性がなくなるので、旧フォーマットと新フォーマットの変換機能を実装する。
* 旧フォーマットから新フォーマットへの変換は必須（フォーマット変換をおこなわず新旧フォーマット両方を取り扱うという選択肢もあるが、メリットがないと判断）。
  * WALのランダムアクセス化の方式により、作業ボリュームは変わるが、作業期間は次のように見積もる。
  * 旧 => 新フォーマット変換 + 起動時の自動フォーマット変換 1.5日
  * 新 => 旧フォーマット変換するコマンドラインツール 1.5日
* レプリケーション同期機能を実験的実装と位置づけ対応しないという選択肢もあるかもしれない。
* WALフォーマットのバージョンアップに併せて、ローテーションしたWALへのEOFマーカーの追加する。
  * EOFマーカーは高速に読めるようにする(先頭から読まなくてもEOFマーカーだけ読める)
  * EOFマーカーを持つWALは追記されない、したがって変更されることもない。
  * EOFマーカーに当該WALの最初と最後のEpoch値を記録する。
  * LimestoneはEOFマーカー以降のデータを処理しない。
  * 3日と見積もる


### 5.3 WAL履歴情報保存

* 起動時にWALの履歴情報を保存する
* 0.5日
* 履歴専用ファイルの採用が前提
* さらにフォーマットバージョンアップが必要になるが、WALのランダムアクセス化の実装に含むものとし、このモジュールの工数には積まない。


### 5.4 gRPC対応

* gRPCサーバへのサービス登録とクライアントの共通部分
* gRPCサーバは、Limestoneと別モジュールがTsurugi内で動作する前提
* gRPCを用いた通信は、機能を実現するために最低限必要なものを想定している。
* メッセージフォーマットは、各メッセージを使用する機能の実装時に詳細を決定する。
* limestoneのUT用にLimestone内でgRPCサーバを起動する機能も必要。
* gRPC Server Streaming RPCを利用してオブジェクトのコピーについての調査
* 見積もりは7日、gRPCの仕様調査や、使用方法の習得を含む見積もり



### 5.5 リモートバックアップサービス

* エポック値の提供
  * 0.5日
* WAL の互換性情報の提供
  * 0.5日
* セッション
  * セッション有効中は、BLOBファイルのGCを停止する機能を含む。
  * 2日
* バックアップへ要求への応答
  * 増分バックアップ + フルバックアップ
  * 増分バックアップについては、単にファイルリストのコピーではなく、ファイルの一部をコピーする必要があるので、それをどう処理するのかを検討する必要がある。この検討の工数も含む。
  * 3日
* Tsurugi停止時に、リモートバックアップサービスを提供するサーバの実装
  * 2日
* オブジェクトデータのコピー
  * TCPでのコピー、またはgRPC server Streaming RPCのどちらかで実装する。
  * 最低限のレプリケーション機能開発で作成したBLOBのコピー機能を流用する。
  * 8日と見込んでいる。
  * 性能測定とチューニングに4日を見込んでいる（8日はこの4日を含む）。


### 5.6 レプリカ同期クライアント

* リモートバックアップサービスを通して、リモートノードのEpoch値を取得、表示
  * 2H
* 自ノードのEpoch値の取得、表示
  * 2H
* WAL の互換性を検証
  * 0.5日
* WAL同期機能
  * 4日
* CLIコマンド
  * 2日


### 5.7 結合レベルのUT

* これまでのタスクの見積もりはモジュール単位のUT作成まで
* 各機能を結合して動作するUTの作成とバグ修正の期間として5日を見積もる


### 5.8 tsurugidbへの組み込み

* tsurugidbへ組み込んだ状態での動作確認、簡易な性能測定、バグ修正
* Walkthroughで確認したシナリオのテスト
* 5日と見積もる


### 5.9 ログ

* 運用・デバッグのためのログ出力は各モジュールの見積もりに含める
* 全体として適切なログ出力が行われているかの確認はtsurugidbへの組み込みの期間に含める
* Altimeter向けのログ出力について1日を見積もる


### 5.10 設定ファイル
* 設定ファイルの設定項目の整理、デフォルト値の設定など
* Tsurugi停止時にリモートバックアップサービスを提供するサーバが設定ファイルを読む機能を含む
  * 既存コードを流用できる前提
* 2日と見積もる
* 実際の設定ファイルのパースなどはlimestone外で行うものとし、limestoneは既存のI/Fで設定情報を受け取ることを想定
* 工数見積もりはlimestone側の作業のみの見積もり


### 5.11 ドキュメント
* 一通りの作業が終了した後のドキュメントの整理
* CLIコマンドのリファレンス作成
* セットアップに関する資料
* 5日と見積もる



## 6. 補足情報


### 6.1 WALの互換性情報とWAL履歴情報の違い

WALの互換性情報とWAL履歴情報は、保持する内容としては現時点では同一であるが、用途と提供経路が異なるため、別の名称を用いている。

- **記録内容の前提**  
  実際に記録しているのは「Epoch値」と「UUID」のペアであり、いわゆる系列IDやブランチIDはこの情報に対して後から付与される意味付けに過ぎない。  
  例えば、UUIDが異なれば異なる系列とみなすことができるが、UUID自体は単なる識別用の値である。

- **WAL履歴情報**  
  データベース内部で永続的に保持される情報であり、過去から現在までの (Epoch, UUID) の変遷をすべて記録する。将来的には、この履歴を利用して系列の分岐点や巻き戻し可能な位置を特定し、より高度な同期処理や障害復旧の判断に活用する。

- **WAL互換性情報**  
  APIを通じて外部に提供される、同期可否の判定に必要な情報。現状ではWAL履歴情報と同じ (Epoch, UUID) のペアを返すが、将来は必要部分のみ、または別形式で返す可能性がある。内部構造や全履歴をそのまま公開する必要はなく、同期判定に必要な最小限の情報とすることも可能である。

このように、現状では保持する内容は同一であっても、内部管理用（履歴情報）と外部提供用（互換性情報）を分離しておくことで、将来の拡張や仕様変更に柔軟に対応できる設計としている。

## プロトコル





## プロトコル(参考情報)

### プロトコル案: メタ情報の取得

```proto
// request information of the remote backup service.
message request.GetInfo {
    // message version
    uint64 version = 1;
}
```

```proto
// response of request.GetInfo.
message response.GetInfo {
    // the last epoch number.
    uint64 last_epoch = 2;

    // list of branch epochs for validate history of epochs.
    repeated BranchEpoch branches = 3;
}

// an entry of branch epoch for validate history of epochs.
message response.BranchEpoch {
    // the epoch number.
    uint64 epoch = 1;

    // the identity of the epoch.
    uint64 identity = 2;
}
```

### プロトコル案: バックアップセッションの開始

```proto
// request to begin a new backup session.
message request.BeginBackup {
    // message version
    uint64 version = 1;

    // the epoch number to start backup (inclusive), or 0 to start from the beginning.
    uint64 begin_epoch = 2;

    // the epoch number to end backup (exclusive), or 0 to end at the current epoch.
    uint64 end_epoch = 3;
}
```

```proto
// response of request.BeginBackup.
message response.BeginBackup {
    // the session ID.
    string session_id = 1;

    // the epoch number to start backup (inclusive), or 0 means this is full-backup.
    uint64 start_epoch = 2;

    // the epoch number to end backup (exclusive), or 0 means there is no data to backup.
    uint64 finish_epoch = 3;

    // the list of objects to backup.
    repeated BackupObject objects = 4;
}

// represents an object to backup.
message response.BackupObject {
    // the object ID
    string id = 1;

    // the object type.
    ObjectType type = 2;

    // the relative path of the object, relative to the container root of the its object type.
    string path = 3;
}

// represents the kind of the object to backup.
enum ObjectType {

    // unknown object type.
    UNSPECIFIED = 0;

    // WAL file.
    LOG = 1;

    // piece of snapshot files.
    SNAPSHOT = 2;

    // BLOB file.
    BLOB = 3;

    // metadata.
    METADATA = 4;
}
```

* TBD
  * セッション開始時に、データ転送経路についてのリクエストを送りたい
    * どの転送経路を要求するかをリクエストに含める
    * レスポンスには、実際のデータ転送経路の情報を含める (シークレット含む)

### プロトコル案: バックアップセッションの延長

```proto
// request to extend the current backup session.
message request.KeepAlive {
    // message version
    uint64 version = 1;

    // the session ID.
    string session_id = 2;
}
```

```proto
// response of request.KeepAlive.
message response.KeepAlive {
    // request was successful.
    google.protobuf.Empty success = 1;
    // request was failed.
    Error error = 2;
}
```

### プロトコル案: バックアップセッションの終了

```proto
// request to end the current backup session.
message request.EndBackup {
    // message version
    uint64 version = 1;

    // the session ID.
    string session_id = 2;
}
```

```proto
// response of request.EndBackup.
message response.EndBackup {
    // no special fields.
}
```

### プロトコル案: オブジェクトデータの取得

```proto
// request to get an object data from the remote backup service.
message request.GetObject {
     // message version
    uint64 version = 1;

    // the session ID.
    string session_id = 2;
 
    // the object ID.
    string object_id = 3;
}
```

```proto
// response of request.GetObject.
message response.GetObject {
    // the size of the object data.
    uint64 size = 1;
}
```

上記とは別に、オブジェクトデータをデータ転送系から受け取る。
データ転送中は次の `GetObject` リクエストは失敗する。

代替案として、gRPC の Server Streaming RPC を利用してオブジェクトデータを転送してもよい。
性能を考慮しない場合、これが構成的に一番簡素になる。
以下はメッセージの例。

```proto
message request.GetObjectData {
     // message version
    uint64 version = 1;

    // the session ID.
    string session_id = 2;
 
    // the object ID.
    string object_id = 3;
}
```

```proto
message response.GetObjectData {
    // the object data chunk.
    bytes chunk = 1;
}
```