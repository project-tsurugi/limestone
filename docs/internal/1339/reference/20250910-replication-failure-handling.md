# レプリケーション障害に対する取り扱い

2025-09-10 arakawa (NT)

## この文書について

* Tsurugi のレプリケーション機能において、一部のレプリカが応答しない、またはエラーを返す場合の取り扱いを定義

## コンセプト

* 正常な応答が可能なレプリカの数 (残存レプリカ数) に応じて、個々のレプリカへの転送失敗時の挙動をスイッチする
* 残存レプリカ数の閾値を設定可能にし、構成ごとの要求に柔軟に対応する
  * 例: 過半数を下回ったらアボート、レプリカが全滅しても継続、など

## 用語

* プレコミット
  * コミット操作のうち、トランザクション単位で行う
  * プレコミットに成功すると、そのトランザクションの結果をインデックスに反映させる
  * 同一のエポックでプレコミットに成功したトランザクションをまとめて、グループコミットへと移行する
  * プレコミットに失敗したら、当該トランザクションはグループコミットに参加せず、アボートする
* グループコミット
  * コミット操作のうち、プレコミット成功後にエポック単位で行う
  * ローカルディスクに永続化を行うローカルコミットと、レプリカ上での永続化を行うレプリケーションコミットに分かれる
* ローカルコミット
  * グループコミットのうち、マスターが自身のローカルディスクに対して行う
  * ローカルコミットに成功すると、マスターのログに対象エポックに含まれるトランザクションの結果を反映させた状態となる
  * ローカルコミットに失敗した場合、当該エポックに含まれるすべてのトランザクションをアボートする
* レプリケーションコミット
  * グループコミットのうち、マスターが各レプリカに対して行う
  * レプリケーションコミットに成功すると、規定数以上のレプリカのログに対象エポックに含まれるトランザクションの結果を反映させた状態となる
  * レプリケーションコミットに失敗した場合、当該エポックに含まれるすべてのトランザクションをアボートする

----
備考:

* 実装上、ローカルコミットが失敗した時点で、レプリケーションコミットは自動的に失敗する
  * これは、レプリケーションコミットは成功したが、ローカルコミットに失敗した、という不安定な状態の発生を防ぐための措置
* 実装上、グループコミット中に失敗した場合、カスケーディングアボートが発生する
  * 例: エポック E<sub>n</sub> のグループコミットに失敗した場合、その時点で未コミットの E<sub>n</sub> 以降のすべてのトランザクションをアボートする

## 残存レプリカ数の閾値

マスターが各レプリカに対してエポック内のログを転送する際、残存レプリカ数に対し以下の 2 種類の閾値を導入する:

* 確定数 (コミット確定レプリカ数)
  * レプリケーションコミットを確定させるために **十分な** レプリカ数
  * マスターから見て、確定数以上のレプリカにログの転送に成功した時点で、そのレプリケーションコミットを成功とみなす
* 維持数 (システム維持レプリカ数)
  * システムの継続のために **必要な** レプリカ数
  * マスターから見て、維持数以上のレプリカにログを転送できなかったら、そのレプリケーションコミットを失敗とみなす

つまり、最低でも維持数のレプリカに対してログの転送を成功させれば、レプリケーションコミットを成功とみなせる。

なお、各閾値は以下の制約を満たすものとする:

```txt
0 <= 維持数 <= 確定数 <= 総レプリカ数
```

確定数と維持数は、 ユーザーが設定可能なパラメータとする。

----
備考:

* 多くの分散システムにおいては、確定数 = 維持数 = 定足数 (quorum) > 母数 / 2 とすることが多い
  * これは、split brain 等を防止するための措置でもある
* サービス継続性の観点から、システムを継続するための維持数を柔軟に設定できるようにする
  * 維持数 = 0 とすれば、マスターだけが生き残っている状態でもシステムを継続できる
  * split brain については、上位の運用で回避する (上位の制御層において、複数マスターの存在を許さない等)

## マスターの動作モード

残存レプリカ数に応じて、マスターは以下の 3 種類の動作モードを持つ:

* 正常モード - 残存レプリカ数 >= 確定数 の場合:
  * データベースクラスターが正常に動作している段階
  * マスターは確定数以上のレプリカへ、ログの転送に成功した時点で、そのレプリケーションコミットを **成功** とみなす
    * 以降は、バックグラウンドで残りのレプリカへの転送を継続する
  * ログ転送の失敗や、タイムアウトによって成功件数が確定数に達しなかった場合、閾値ごとに以下のように判断する:
    * 転送に成功したレプリカが維持数を超えていれば、そのレプリケーションコミットを **準成功** とみなす (縮退モードに移行)
    * そうでなければ、そのレプリケーションコミットを **失敗** とみなす (閉塞モードに移行)
* 縮退モード - 確定数 > 残存レプリカ数 >= 維持数 の場合:
  * データベースクラスターに十分なレプリカが存在せず、応答性能の低下やデータ損失のリスクがある状態
  * マスターはすべての残存レプリカからの応答を待ち、応答が返ってきた、またはタイムアウトした時点で、そのレプリケーションコミットの成否を判断する
    * 転送に成功したレプリカが維持数を超えていれば、そのレプリケーションコミットを **準成功** とみなす
    * そうでなければ、そのレプリケーションコミットを **失敗** とみなす (閉塞モードに移行)
* 閉塞モード - 維持数 > 残存レプリカ数 の場合:
  * データベースクラスターの維持に必要なレプリカが存在しないため、運転を停止している状態
  * トランザクションは閉塞モードにあり、新しいトランザクションの開始は行えず、またレプリケーションコミットが成功していないすべてのトランザクションはアボートする
  * クラスターにレプリカが追加され、維持数以上のレプリカが存在する状態になると、閉塞を解除できる

レプリケーションコミットの状態と取り扱いは以下の通り:

| 状態   | データベース内部の挙動 | ユーザーへの通知                 |
|--------|------------------------|----------------------------------|
| 成功   | コミットが正常に終了   | コミットが正常に終了             |
| 準成功 | コミットが正常に終了   | コミットが警告付きで正常に終了   |
| 失敗   | コミットをアボート     | コミットが失敗                   |

----
備考:

* 正常モードにおいては、確定数に達した時点で応答を返すことで、レイテンシーを抑える
* 縮退モードにおいては、すべてのレプリカの応答を待つことで、データ損失のリスクを抑える
* 残存レプリカ数が減少した際、ログやメトリクス等で監視機構に通知を行う

## ログの転送とレプリカの切り離し

* マスターは、レプリカへのログ転送に失敗した場合、そのレプリカを切り離す
  * レプリカは、マスターからのログ転送に対し、 ACK / NACK で応答する
    * ACK が返ってきたら転送成功、 NACK が返ってきたら転送失敗とみなす
    * ACK, NACK のいずれかを返す前に、ログの再転送を要求してもよい (データ破損時など)
  * マスターは、レプリカからの応答が一定時間以内に帰ってこなかった場合、転送失敗とみなす (レプリカタイムアウト)
    * マスターは、必要に応じて転送を複数回試行してもよい (ネットワーク瞬断対策)
* レプリカを切り離した場合、マスターは以降当該レプリカに対してログ転送を行わない
* レプリカを追加したり切り離したりする場合、マスターは残存レプリカ数のカウントを更新する

----
備考:

* レプリカが ACK をどのタイミングで返すかについては、設定で調整する
  * (1) ログを受信した時点で ACK を返す
  * (2) ログを永続化した時点で ACK を返す
* レプリカの追加に関しては本文書の範囲外とする

## 動作モードごとの挙動

残存レプリカ数と各種閾値に応じて、マスターの動作モードを切り替える。
以降では、各モードにおける挙動を紹介する。

### 正常モード・縮退モードの挙動

正常モードや縮退モードでは、維持数以上のレプリカが存在する。
2つのモードはおおよその挙動が同じであるため、まとめて紹介する。

正常モード・縮退モードにおける挙動は以下の通り:

* (1) Limestone は、各レプリカにログを転送し、応答を待機する
* (2) Limestone は、成功の応答を返したレプリカの数に応じて、以下のように判断する:
  * (2.1) 成功の応答を返したレプリカ数が、確定数以上となった場合:
    * Limestone は、Shirakami に **コミット成功イベント** を通知する
    * 未応答のレプリカについては、バックグラウンドで応答の待機を継続する
  * (2.2) すべてのレプリカからの応答を待ち終えたが、成功の応答を返したレプリカ数が確定数未満かつ、維持数以上の場合:
    * Limestone は、Shirakami に **警告付きコミット成功イベント** を通知する
  * (2.3) すべてのレプリカからの応答を待ち終えたが、成功の応答を返したレプリカ数が維持数未満の場合:
    * Limestone は閉塞モードへと移行し、閉塞モードの処理を開始する
* (3) Limestone は、失敗の応答を返したレプリカ、およびタイムアウトしたレプリカを[切り離す](#ログの転送とレプリカの切り離し)
* (4) Shirakami は、Limestone からのイベントを Jogasaki に通知する
* (5) Jogasaki は、 Shirakami からのイベントをクライアントに通知する

### 閉塞モードの挙動

閉塞モードでは、維持数を下回るレプリカしか存在しない。
閉塞モード下では、すべてのレプリケーションコミットが失敗する。

閉塞モードにおける挙動は以下の通り:

* (1) Limestone は、リワインドを開始する
* (2) Limestone は、リワインドの開始後、 Shirakami に対してレプリケーションコミットの失敗を通知する
* (3) Shirakami は、リワインドを開始する
* (4) Shirakami は、リワインドの開始後、 Jogasaki に対してレプリケーションコミットの失敗を通知する
* (5) Jogasaki は、クライアントに対してレプリケーションコミットの失敗を通知する

各コンポーネントにおけるリワインドの処理については、[リワインドの挙動](#リワインドの挙動) の項で紹介する。
閉塞モードからほかのモードへの遷移は、[閉塞状態からの復帰](#閉塞状態からの復帰) の項で紹介する。

----
備考:

* 簡単のため挙動を上記のように書いたが、実際にはレプリケーションコミットがカスケードして行われる可能性がある
  * エラーの通知は必ずエポックの順番に合わせ、前後してはならない
  * エラーが複数回通知されるため、Limestone, Shirakami 内でリワインドが複数回行われるが、冪等であるため問題はない

## リワインドの挙動

レプリカへの転送成功数が維持数を下回った場合、当該レプリケーションコミットは失敗する。
このとき、それぞれのコンポーネントはリワインド (巻き戻し) を行う。

リワインドは、コミットの各段階で確定させた内容を取り消し、コミットの開始前の状態に戻す操作。
基本的には「プレコミット → ローカルコミット → レプリケーションコミット」の順に処理を行い、
後段でエラーが発生した際には、前段までの処理を取り消す必要がある。

以降では、レプリケーションコミット失敗時のリワインドについて紹介する。

### リワインドの挙動: Limestone

前提:

* エポック E<sub>n</sub> のローカルコミットに成功し、レプリケーションコミットに失敗した
* レプリカ R<sub>i..j</sub> へのログ転送にはすでに成功している状態

全体の挙動:

* (1) Limestone を閉塞し、以降のグループコミットの要求を自動的に失敗させる
* (2) 未完了のグループコミットをすべて失敗させる
* (2) ローカルのログを E<sub>n-1</sub> の状態にリワインドする
* (3) レプリカ R<sub>i..j</sub> に対し、(2) と同様の処理を依頼する

ログのリワインドの挙動:

* 永続化に成功したエポックが E<sub>n</sub> 以上であれば、 E<sub>n-1</sub> に書き直す
* P-WAL ファイルのうち、 E<sub>n</sub> 以上のエントリを無効化する

### リワインドの挙動: Shirakami

前提:

* エポック E<sub>n</sub> のレプリケーションコミット失敗が、Limestone から通知された

全体挙動:

* (1) Shirakami を閉塞し、以降のトランザクションの要求を自動的に失敗させる
* (2) 現在グループコミットを開始していない、すべてのトランザクションをアボートする
* (3) インデックス上の変更を E<sub>n-1</sub> の状態にリワインドする

インデックスのリワインドは、主に以下の2つの方法が考えられる:

* (a) インデックス上の、 E<sub>n-1</sub> よりも後 (exclusive) のエポックにおいて追加したバージョンを削除する
* (b) Limestone 上の E<sub>n-1</sub> までのログから、インデックスを再構築する

いずれかの方法で、閉塞が解除されるまでにリワインドを完了させる。

----
議論:

インデックスの各リワインド方式について、Pros./Cons. を以下にまとめる。

* (a) インデックス上の、 E<sub>n-1</sub> よりも後 (exclusive) のエポックにおいて追加したバージョンを削除する
  * Pros.
    * 比較的高速にリワインド可能
  * Cons.
    * インデックスエントリに対し、追加したエポック番号の情報が必要
    * レプリケーションコミット成功まで GC 対象から除外する必要がある
      * → バージョンリストが肥大化し、パフォーマンスに影響が出る可能性がある
* (b) Limestone 上の E<sub>n-1</sub> までのログから、インデックスを再構築する
  * Pros.
    * 実装が容易
      * データベース起動時のインデックスリストア処理相当
  * Cons.
    * リワインドに時間がかかる可能性がある
      * 事前に [Linestone のリワインド](#リワインドの挙動-limestone) を完了させておく必要がある
      * ただし、閉塞解除前までに完了させればよいので、それほど影響は大きくない可能性はある

なお、レプリケーション関連でのリワインドは、復帰までに時間がかかる想定であるが、
[分散トランザクション](#分散トランザクションとの関連) (トランザクション同期) においては、
ほかのノードの失敗に巻き込まれただけの一時的なエラーである場合がある。
この場合には、リワインドをできるだけ高速に完了させることが望ましい。

### リワインドの挙動: Jogasaki

Jogasaki では、特にリワインドの処理は行わない。
なお、隣接する Shirakami が閉塞しているため、トランザクションに関連する処理はすべて失敗する。

## 閉塞状態からの復帰

レプリケーションコミット時に、残存レプリカ数が維持数を下回った場合、マスターは閉塞モードに移行する。
このモードに移行すると、Shirakami や Limestone が閉塞状態へと移行するため、トランザクションの実行が行えなくなる。

以下では、それぞれのコンポーネントにおいて、閉塞状態から復帰するための条件を紹介する。

### 閉塞状態からの復帰: Limestone

Limestone の閉塞状態を解除するには、以下のすべてを満たす必要がある:

* ログのリワインドが完了している
* 利用可能なレプリカが維持数以上存在する
* 外部から閉塞解除の要求があった

なお、利用可能なレプリカは、Limestone の (リワインド後の) ローカルのログと、同じエポックのログを有している必要がある。

Limestone の閉塞が解除された場合、以下の動作を行う:

* Limestone の動作モードを、残存レプリカ数に応じて、正常モードまたは縮退モードに切り替える
* Shirakami に対し、Limestone の閉塞解除を通知する

----
備考:

* 外部からの要求が必要なのは、意図しない復帰による輻輳等を回避するため
  * 上位の制御システムにより自動化するのは構わない

### 閉塞状態からの復帰: Shirakami

Shirakami の閉塞状態を解除するには、以下のすべてを満たす必要がある。

* インデックスのリワインドが完了している
* Limestone の閉塞が解除されている

Shirakami の閉塞が解除された場合、以下の動作を行う:

* Jogasaki に対し、Shirakami の閉塞解除を通知する

## 付録

### 分散トランザクションとの関連

(現状における) 分散トランザクションの基本的な考え方:

* 分散トランザクションに参加する各ノードにおいて、以下のようなバリアの組を共有する
  * (1) プレコミット開始のバリア
  * (2) コミットベリファイ成功のバリア (インデックス反映前)
  * (3) グループコミット完了のバリア
* 分散トランザクションに関連する各トランザクションは、全員が各バリアに到達するまで、次の段階に進めない
  * 誰か一人でもバリアに失敗を通知すると、参加する全員が失敗扱いになる
  * 誰か一人でもバリアのタイムアウトに達すると、同様に全員が失敗扱いになる

バリアに到達したが、他の参加者によって全体が失敗となった場合、以下のように処理を行う:

* (1) プレコミット開始のバリアに到達したが、失敗となった場合:
  * 当該トランザクションをアボートさせる
* (2) コミットベリファイ成功のバリアに到達したが、失敗となった場合:
  * 当該トランザクションをアボートさせる
* (3) ローカルコミット完了のバリアに到達したが、失敗となった場合:
  * 当該コミットを含むグループコミットをアボートさせる
  * さらに、 [リワインドの処理](#リワインドの挙動)を行う
    * 自身が原因の失敗でない場合、閉塞はリワインドを実施する間の一時的なものであり、リワインド完了後に即座に閉塞を解除できる
    * 自身が原因の失敗である場合、閉塞は各条件を満たすまで解除できない
